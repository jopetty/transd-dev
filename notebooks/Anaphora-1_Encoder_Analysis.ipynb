{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis for `anaphora-1` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from hydra import compose, initialize, initialize_config_dir, initialize_config_module\n",
    "from hydra.utils import instantiate\n",
    "from matplotlib import pyplot as plt\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_from_ckpt(exp_path):\n",
    "    config_name = \"config\"\n",
    "    wandb_path = \"wandb/latest-run/files/\"\n",
    "    exp_dir = os.path.abspath(os.path.join(\"../\", exp_path))\n",
    "    ckpt_dir = os.path.abspath(os.path.join(\"../\", exp_path, \"checkpoints\"))\n",
    "    ckpt_path = os.path.join(ckpt_dir, \"last.ckpt\")\n",
    "    saved_wandb_dir = os.path.abspath(os.path.join(\"../\", exp_path, wandb_path))\n",
    "    saved_cfg_dir = os.path.join(exp_dir, \".hydra\")\n",
    "\n",
    "    assert os.path.exists(f\"{saved_cfg_dir}/{config_name}.yaml\")\n",
    "    assert os.path.exists(f\"{saved_wandb_dir}/{config_name}.yaml\")\n",
    "\n",
    "    cfgs = {}\n",
    "\n",
    "    with initialize_config_dir(version_base=\"1.1\", config_dir=saved_cfg_dir):\n",
    "        cfg = compose(config_name=config_name)\n",
    "        cfgs[\"hydra\"] = cfg\n",
    "\n",
    "    with initialize_config_dir(version_base=\"1.1\", config_dir=saved_wandb_dir):\n",
    "        cfg = compose(config_name=config_name)\n",
    "        cfgs[\"wandb\"] = cfg\n",
    "\n",
    "    model = create_model(cfgs)\n",
    "    model = model.__class__.load_from_checkpoint(ckpt_path)\n",
    "    model.eval()\n",
    "\n",
    "    datamodule = create_datamodule(cfgs)\n",
    "\n",
    "    return model, datamodule\n",
    "\n",
    "\n",
    "def create_datamodule(cfgs):\n",
    "    datamodule_cfg = cfgs[\"hydra\"].datamodule\n",
    "    data_dir = cfgs[\"wandb\"][\"datamodule/data_dir\"].value\n",
    "\n",
    "    with open_dict(datamodule_cfg):\n",
    "        datamodule_cfg.data_dir = data_dir\n",
    "\n",
    "    datamodule: LightningDataModule = instantiate(datamodule_cfg)\n",
    "    return datamodule\n",
    "\n",
    "\n",
    "def create_model(cfgs):\n",
    "    model_cfg = cfgs[\"hydra\"].model\n",
    "    dec_vocab_size = cfgs[\"wandb\"][\"model/dec_vocab_size\"].value\n",
    "    enc_vocab_size = cfgs[\"wandb\"][\"model/enc_vocab_size\"].value\n",
    "    dec_EOS_idx = cfgs[\"wandb\"][\"model/dec_EOS_idx\"].value\n",
    "    with open_dict(model_cfg):\n",
    "        model_cfg.dec_vocab_size = dec_vocab_size\n",
    "        model_cfg.enc_vocab_size = enc_vocab_size\n",
    "        model_cfg.dec_EOS_idx = dec_EOS_idx\n",
    "\n",
    "    model: LightningModule = instantiate(model_cfg)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model, datamodule = get_model_from_ckpt(\n",
    "    # exp_path=\"outputs/anaphora-1/2022-09-12_16-14-42\"\n",
    "    exp_path=\"outputs/SCAN (Add Jump)/2022-10-02_11-43-28\"\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the entire dataset.\n",
    "# Compute the last-state encodings of each input,\n",
    "# and stack the results into a (D,H)-sized tensor,\n",
    "# where D = length of dataset and H = encoder hidden\n",
    "# size.\n",
    "#\n",
    "# Perform k=2 PCA on this to create a (D,2)-sized tensor\n",
    "# for analysis\n",
    "\n",
    "data_encodings = None\n",
    "data_inputs = None\n",
    "data_preds = None\n",
    "data_target = None\n",
    "\n",
    "for dl in [\n",
    "    datamodule.train_dataloader(),\n",
    "    datamodule.val_dataloader(),\n",
    "    datamodule.test_dataloader(),\n",
    "    # datamodule.gen_dataloader(),\n",
    "]:\n",
    "    for batch in dl:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            batch_enc = model.get_encodings(batch)[\"encoder_last_state\"]\n",
    "            _, preds, target = model.step(batch)\n",
    "\n",
    "        if data_encodings is not None:\n",
    "\n",
    "            data_encodings = torch.cat((data_encodings, batch_enc), dim=0)\n",
    "            data_preds = torch.cat((data_preds, preds), dim=0)\n",
    "            data_target = torch.cat((data_target, target), dim=0)\n",
    "\n",
    "            # print(data_inputs.shape, batch[0].shape)\n",
    "\n",
    "            # Pad input tensors if lengths are wrong\n",
    "            i_size = max(data_inputs.shape[1], batch[0].shape[1])\n",
    "            i_delta = i_size - min(data_inputs.shape[1], batch[0].shape[1])\n",
    "            if i_size > data_inputs.shape[1]:\n",
    "                data_inputs = F.pad(data_inputs, (0, i_delta), \"constant\", 0)\n",
    "                batch_0 = batch[0]\n",
    "                # print(f\"batch[0] was bigger, so i'm padding data_inputs from {data_inputs.shape[1]} to {i_size}\")\n",
    "                # print(\"data_inputs:\", data_inputs.shape)\n",
    "            elif i_size > batch[0].shape[1]:\n",
    "                # print(f\"data_inputs was bigger, so i'm padding batch[0] from {batch[0].shape[1]} to {i_size}\")\n",
    "                batch_0 = F.pad(batch[0], (0, i_delta), \"constant\", 0)\n",
    "                # print(\"batch[0]:\", batch_0.shape)\n",
    "            else:\n",
    "                # print(\"Equal! No padding required\")\n",
    "                batch_0 = batch[0]\n",
    "\n",
    "            data_inputs = torch.cat((data_inputs, batch_0), dim=0)\n",
    "\n",
    "            # # pad tensors if length is wrong\n",
    "            # for (d, t) in [(data_inputs, batch[0]), (data_preds, preds), (data_target, target)]:\n",
    "            #     d_t_size = max(d.shape[1], t.shape[1])\n",
    "            #     if d_t_size > d.shape[1]:\n",
    "            #         d = F.pad(d, (0, d_t_size), \"constant\", 0)\n",
    "            #     elif d_t_size > t.shape[1]:\n",
    "            #         t = F.pad(d, (0, d_t_size), \"constant\", 0)\n",
    "\n",
    "            # data_inputs = torch.cat((data_inputs, batch[0]), dim=0)\n",
    "\n",
    "        else:\n",
    "            data_encodings = batch_enc\n",
    "            data_inputs = batch[0]\n",
    "            data_preds = preds\n",
    "            data_target = target\n",
    "\n",
    "if len(data_encodings.shape) > 2:\n",
    "    if data_encodings.shape[1] > 1:\n",
    "        # only look at the last layer\n",
    "        data_encodings = data_encodings[:, 1, :]\n",
    "    data_encodings = torch.squeeze(data_encodings)\n",
    "\n",
    "# data_encodings = torch.squeeze(data_encodings)\n",
    "\n",
    "i_labels = [\n",
    "    datamodule.data_train.dataset.convert_tokens_to_string(k, col=\"source\")\n",
    "    for _, k in enumerate(data_inputs)\n",
    "]\n",
    "i_labels = [\" \".join(l) for l in i_labels]\n",
    "\n",
    "t_labels = [\n",
    "    datamodule.data_train.dataset.convert_tokens_to_string(k, col=\"target\")\n",
    "    for _, k in enumerate(data_target)\n",
    "]\n",
    "t_labels = [\" \".join(l) for l in t_labels]\n",
    "\n",
    "p_labels = [\n",
    "    datamodule.data_train.dataset.convert_tokens_to_string(k, col=\"target\")\n",
    "    for _, k in enumerate(data_preds)\n",
    "]\n",
    "p_labels = [\" \".join(l) for l in p_labels]\n",
    "\n",
    "pt_pca = torch.pca_lowrank(data_encodings, q=2)\n",
    "pt_reduced_enc = (data_encodings @ pt_pca[2]).detach()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"input\": i_labels,\n",
    "        \"target\": t_labels,\n",
    "        \"prediction\": p_labels,\n",
    "        \"pca1\": pt_reduced_enc[:, 0],\n",
    "        \"pca2\": pt_reduced_enc[:, 1],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"jump\"] = df[\"input\"].str.contains(\"jump\")\n",
    "df[\"walk\"] = df[\"input\"].str.contains(\"walk\")\n",
    "df[\"turn_right\"] = df[\"input\"].str.contains(\"turn right\")\n",
    "df[\"twice\"] = df[\"input\"].str.contains(\"twice\")\n",
    "df[\"jump_twice\"] = df[\"jump\"] & df[\"twice\"]\n",
    "df[\"walk_twice\"] = df[\"walk\"] & df[\"twice\"]\n",
    "df[\"turn_right_twice\"] = df[\"turn_right\"] & df[\"twice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"jump\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"walk\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"twice\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"jump_twice\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"walk_twice\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"himself\"] = df[\"input\"].str.contains(\"himself\")\n",
    "df[\"herself\"] = df[\"input\"].str.contains(\"herself\")\n",
    "df[\"refl\"] = df[\"himself\"] | df[\"herself\"]\n",
    "df[\"alice\"] = df[\"input\"].str.contains(\"alice\")\n",
    "df[\"bob\"] = df[\"input\"].str.contains(\"bob\")\n",
    "df[\"claire\"] = df[\"input\"].str.contains(\"claire\")\n",
    "df[\"knows\"] = df[\"input\"].str.contains(\"knows\")\n",
    "df[\"likes\"] = df[\"input\"].str.contains(\"likes\")\n",
    "df[\"sees\"] = df[\"input\"].str.contains(\"sees\")\n",
    "df[\"alice_refl\"] = df[\"alice\"] & df[\"refl\"]\n",
    "df[\"claire_refl\"] = df[\"claire\"] & df[\"refl\"]\n",
    "df[\"intrans\"] = df[\"input\"].str.contains(\"<PAD>\")\n",
    "\n",
    "\n",
    "int_to_refl = {0: \"non-reflexive\", 1: \"herself\", 2: \"himself\"}\n",
    "df[\"refl_type\"] = df[\"herself\"].apply(int)\n",
    "df[\"refl_type\"] += df[\"himself\"].apply(int).apply(lambda x: 2 * x)\n",
    "df[\"refl_type\"] = df[\"refl_type\"].apply(lambda x: int_to_refl[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"turn_right\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"turn_right_twice\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"intrans\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"refl_type\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"alice\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"bob\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"knows\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"likes\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"sees\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"alice_refl\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"claire_refl\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=df, hue=\"claire\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b85e778a8e54e7353bf671de5cfdc3668fa7adcf13efa74aa48d54e35c541ce6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
