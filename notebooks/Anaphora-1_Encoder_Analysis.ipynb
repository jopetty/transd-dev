{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis for `anaphora-1` models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for this notebook is to perform analysis on the learned encoding space for SRN/GRU models which can successfully solve the `anaphora-1` task.\n",
    "- Specifically, we are interested in how reflexive inputs (e.g., \"Alice sees herself\") are represented in the encoder's hidden space, compared to pseudo reflexive inputs (e.g., \"Alice sees Alice\") and regular transitive expressions (e.g., \"Alice sees Bob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from pytorch_lightning import LightningModule, LightningDataModule\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_from_ckpt(exp_path):\n",
    "    config_name = \"config\"\n",
    "    wandb_path = \"wandb/latest-run/files/\"\n",
    "    exp_dir = os.path.abspath(os.path.join(\"../\",exp_path))\n",
    "    ckpt_dir = os.path.abspath(os.path.join(\"../\", exp_path, \"checkpoints\"))\n",
    "    ckpt_path = os.path.join(ckpt_dir, 'last.ckpt')\n",
    "    saved_wandb_dir = os.path.abspath(os.path.join(\"../\", exp_path, wandb_path))\n",
    "    saved_cfg_dir = os.path.join(exp_dir, \".hydra\")\n",
    "\n",
    "    assert os.path.exists(f\"{saved_cfg_dir}/{config_name}.yaml\")\n",
    "    assert os.path.exists(f\"{saved_wandb_dir}/{config_name}.yaml\")\n",
    "\n",
    "    cfgs = {}\n",
    "\n",
    "    with initialize_config_dir(version_base = \"1.1\", config_dir=saved_cfg_dir):\n",
    "        cfg = compose(config_name=config_name)\n",
    "        cfgs[\"hydra\"] = cfg\n",
    "    \n",
    "    with initialize_config_dir(version_base = \"1.1\", config_dir=saved_wandb_dir):\n",
    "        cfg = compose(config_name=config_name)\n",
    "        cfgs[\"wandb\"] = cfg\n",
    "    \n",
    "    model = create_model(cfgs)\n",
    "    model = model.__class__.load_from_checkpoint(ckpt_path)\n",
    "\n",
    "    datamodule = create_datamodule(cfgs)\n",
    "\n",
    "    return model, datamodule\n",
    "\n",
    "def create_datamodule(cfgs):\n",
    "    datamodule_cfg = cfgs[\"hydra\"].datamodule\n",
    "    data_dir = cfgs[\"wandb\"][\"datamodule/data_dir\"].value\n",
    "\n",
    "    with open_dict(datamodule_cfg):\n",
    "        datamodule_cfg.data_dir = data_dir\n",
    "\n",
    "    datamodule: LightningDataModule = instantiate(datamodule_cfg)\n",
    "    return datamodule\n",
    "\n",
    "def create_model(cfgs):\n",
    "    model_cfg = cfgs[\"hydra\"].model\n",
    "    dec_vocab_size = cfgs[\"wandb\"][\"model/dec_vocab_size\"].value\n",
    "    enc_vocab_size = cfgs[\"wandb\"][\"model/enc_vocab_size\"].value\n",
    "    dec_EOS_idx = cfgs[\"wandb\"][\"model/dec_EOS_idx\"].value\n",
    "    with open_dict(model_cfg):\n",
    "        model_cfg.dec_vocab_size = dec_vocab_size\n",
    "        model_cfg.enc_vocab_size = enc_vocab_size\n",
    "        model_cfg.dec_EOS_idx = dec_EOS_idx\n",
    "    \n",
    "    model: LightningModule = instantiate(model_cfg)\n",
    "\n",
    "    return model\n",
    "    \n",
    "# model, datamodule = get_model_from_ckpt(exp_path=\"outputs/anaphora-1/2022-09-12_17-44-42\")\n",
    "# model, datamodule = get_model_from_ckpt(exp_path=\"outputs/anaphora-1/2022-09-11_23-42-41\")\n",
    "\n",
    "model, datamodule = get_model_from_ckpt(exp_path=\"outputs/anaphora-1/2022-09-12_16-14-42\")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iterate through the entire dataset. \n",
    "# Compute the last-state encodings of each input,\n",
    "# and stack the results into a (D,H)-sized tensor,\n",
    "# where D = length of dataset and H = encoder hidden\n",
    "# size.\n",
    "#\n",
    "# Perform k=2 PCA on this to create a (D,2)-sized tensor\n",
    "# for analysis\n",
    "\n",
    "data_encodings = None\n",
    "data_inputs = None\n",
    "data_preds = None\n",
    "data_target = None\n",
    "\n",
    "for dl in [datamodule.train_dataloader(), datamodule.val_dataloader(), datamodule.test_dataloader(), datamodule.gen_dataloader()]:\n",
    "    for batch in dl:\n",
    "\n",
    "        batch_enc = model.get_encodings(batch)['encoder_last_state']\n",
    "        _, preds, target = model.step(batch)\n",
    "\n",
    "        if data_encodings is not None:\n",
    "            data_encodings = torch.cat((data_encodings, batch_enc), dim=0)\n",
    "            data_inputs = torch.cat((data_inputs, batch[0]), dim=0)\n",
    "            data_preds = torch.cat((data_preds, preds), dim=0)\n",
    "            data_target = torch.cat((data_target, target), dim=0)\n",
    "        else:\n",
    "            data_encodings = batch_enc\n",
    "            data_inputs = batch[0]\n",
    "            data_preds = preds \n",
    "            data_target = target\n",
    "\n",
    "data_encodings = torch.squeeze(data_encodings)\n",
    "\n",
    "i_labels = [datamodule.data_train.dataset.convert_tokens_to_string(k, col='source') for _, k in enumerate(data_inputs)]\n",
    "i_labels = [' '.join(l) for l in i_labels]\n",
    "\n",
    "t_labels = [datamodule.data_train.dataset.convert_tokens_to_string(k, col='target') for _, k in enumerate(data_target)]\n",
    "t_labels = [' '.join(l) for l in t_labels]\n",
    "\n",
    "p_labels = [datamodule.data_train.dataset.convert_tokens_to_string(k, col='target') for _, k in enumerate(data_preds)]\n",
    "p_labels = [' '.join(l) for l in p_labels]\n",
    "\n",
    "pt_pca = torch.pca_lowrank(data_encodings, q=2)\n",
    "pt_reduced_enc = (data_encodings @ pt_pca[2]).detach()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'input': i_labels,\n",
    "    'target': t_labels,\n",
    "    'prediction': p_labels,\n",
    "    'pca1': pt_reduced_enc[:,0],\n",
    "    'pca2': pt_reduced_enc[:,1]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['himself'] = df['input'].str.contains(\"himself\")\n",
    "df['herself'] = df['input'].str.contains(\"herself\")\n",
    "df['refl'] = df['himself'] | df['herself']\n",
    "df['alice'] = df['input'].str.contains(\"alice\")\n",
    "df['bob'] = df['input'].str.contains(\"bob\")\n",
    "df['claire'] = df['input'].str.contains(\"claire\")\n",
    "df['knows'] = df['input'].str.contains(\"knows\")\n",
    "df['likes'] = df['input'].str.contains(\"likes\")\n",
    "df['sees'] = df['input'].str.contains(\"sees\")\n",
    "df['alice_refl'] = df['alice'] & df['refl']\n",
    "df['claire_refl'] = df['claire'] & df['refl']\n",
    "df['intrans'] = df['input'].str.contains(\"<PAD>\")\n",
    "\n",
    "\n",
    "int_to_refl = {0: 'non-reflexive', 1: 'herself', 2: 'himself'}\n",
    "df['refl_type'] = df['herself'].apply(int)\n",
    "df['refl_type'] += df['himself'].apply(int).apply(lambda x: 2*x)\n",
    "df['refl_type'] = df['refl_type'].apply(lambda x: int_to_refl[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot('pca1', 'pca2', data=df, hue='intrans', fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot('pca1', 'pca2', data=df, hue='refl_type', fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot('pca1', 'pca2', data=df, hue='alice', fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot('pca1', 'pca2', data=df, hue='bob', fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot('pca1', 'pca2', data=df, hue='knows', fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot('pca1', 'pca2', data=df, hue='likes', fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot('pca1', 'pca2', data=df, hue='sees', fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot('pca1', 'pca2', data=df, hue='alice_refl', fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot('pca1', 'pca2', data=df, hue='claire_refl', fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot('pca1', 'pca2', data=df, hue='claire', fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b85e778a8e54e7353bf671de5cfdc3668fa7adcf13efa74aa48d54e35c541ce6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
