{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis for `anaphora-1` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from hydra import compose, initialize, initialize_config_dir, initialize_config_module\n",
    "from hydra.utils import instantiate\n",
    "from matplotlib import pyplot as plt\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "from pytorch_lightning import LightningDataModule, LightningModule\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Needed for under-the-hood loading of models by framework\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_from_ckpt(exp_path):\n",
    "    config_name = \"config\"\n",
    "    wandb_path = \"wandb/latest-run/files/\"\n",
    "    exp_dir = os.path.abspath(os.path.join(\"../\", exp_path))\n",
    "    ckpt_dir = os.path.abspath(os.path.join(\"../\", exp_path, \"checkpoints\"))\n",
    "    ckpt_path = os.path.join(ckpt_dir, \"last.ckpt\")\n",
    "    saved_wandb_dir = os.path.abspath(os.path.join(\"../\", exp_path, wandb_path))\n",
    "    saved_cfg_dir = os.path.join(exp_dir, \".hydra\")\n",
    "\n",
    "    assert os.path.exists(f\"{saved_cfg_dir}/{config_name}.yaml\")\n",
    "    assert os.path.exists(f\"{saved_wandb_dir}/{config_name}.yaml\")\n",
    "\n",
    "    cfgs = {}\n",
    "\n",
    "    with initialize_config_dir(version_base=\"1.1\", config_dir=saved_cfg_dir):\n",
    "        cfg = compose(config_name=config_name)\n",
    "        cfgs[\"hydra\"] = cfg\n",
    "\n",
    "    with initialize_config_dir(version_base=\"1.1\", config_dir=saved_wandb_dir):\n",
    "        cfg = compose(config_name=config_name)\n",
    "        cfgs[\"wandb\"] = cfg\n",
    "\n",
    "    model = create_model(cfgs)\n",
    "    model = model.__class__.load_from_checkpoint(ckpt_path)\n",
    "    model.eval()\n",
    "\n",
    "    datamodule = create_datamodule(cfgs)\n",
    "\n",
    "    return model, datamodule\n",
    "\n",
    "\n",
    "def create_datamodule(cfgs):\n",
    "    datamodule_cfg = cfgs[\"hydra\"].datamodule\n",
    "    data_dir = cfgs[\"wandb\"][\"datamodule/data_dir\"].value\n",
    "\n",
    "    with open_dict(datamodule_cfg):\n",
    "        datamodule_cfg.data_dir = data_dir\n",
    "\n",
    "    datamodule: LightningDataModule = instantiate(datamodule_cfg)\n",
    "    return datamodule\n",
    "\n",
    "\n",
    "def create_model(cfgs):\n",
    "    model_cfg = cfgs[\"hydra\"].model\n",
    "    dec_vocab_size = cfgs[\"wandb\"][\"model/dec_vocab_size\"].value\n",
    "    enc_vocab_size = cfgs[\"wandb\"][\"model/enc_vocab_size\"].value\n",
    "    dec_EOS_idx = cfgs[\"wandb\"][\"model/dec_EOS_idx\"].value\n",
    "    with open_dict(model_cfg):\n",
    "        model_cfg.dec_vocab_size = dec_vocab_size\n",
    "        model_cfg.enc_vocab_size = enc_vocab_size\n",
    "        model_cfg.dec_EOS_idx = dec_EOS_idx\n",
    "\n",
    "    model: LightningModule = instantiate(model_cfg)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the entire dataset.\n",
    "# Compute the last-state encodings of each input,\n",
    "# and stack the results into a (D,H)-sized tensor,\n",
    "# where D = length of dataset and H = encoder hidden\n",
    "# size.\n",
    "#\n",
    "# Perform k=2 PCA on this to create a (D,2)-sized tensor\n",
    "# for analysis\n",
    "\n",
    "\n",
    "def get_analysis_df(model, datamodule, dataloaders):\n",
    "\n",
    "    data_encodings = None\n",
    "    data_inputs = None\n",
    "    data_preds = None\n",
    "    data_target = None\n",
    "\n",
    "    for dl in dataloaders:\n",
    "        for batch in dl:\n",
    "            with torch.no_grad():\n",
    "                batch_enc = model.get_encodings(batch)[\"encoder_last_state\"]\n",
    "                _, preds, target = model.step(batch)\n",
    "\n",
    "            if data_encodings is not None:\n",
    "\n",
    "                data_encodings = torch.cat((data_encodings, batch_enc), dim=0)\n",
    "                data_preds = torch.cat((data_preds, preds), dim=0)\n",
    "                data_target = torch.cat((data_target, target), dim=0)\n",
    "\n",
    "                # Pad input tensors if lengths are wrong\n",
    "                i_size = max(data_inputs.shape[1], batch[0].shape[1])\n",
    "                i_delta = i_size - min(data_inputs.shape[1], batch[0].shape[1])\n",
    "                if i_size > data_inputs.shape[1]:\n",
    "                    data_inputs = F.pad(data_inputs, (0, i_delta), \"constant\", 0)\n",
    "                    batch_0 = batch[0]\n",
    "                elif i_size > batch[0].shape[1]:\n",
    "                    batch_0 = F.pad(batch[0], (0, i_delta), \"constant\", 0)\n",
    "                else:\n",
    "                    batch_0 = batch[0]\n",
    "\n",
    "                data_inputs = torch.cat((data_inputs, batch_0), dim=0)\n",
    "\n",
    "            else:\n",
    "                data_encodings = batch_enc\n",
    "                data_inputs = batch[0]\n",
    "                data_preds = preds\n",
    "                data_target = target\n",
    "\n",
    "    if len(data_encodings.shape) > 2:\n",
    "        if data_encodings.shape[1] > 1:\n",
    "            # only look at the last layer\n",
    "            data_encodings = data_encodings[:, 1, :]\n",
    "        data_encodings = torch.squeeze(data_encodings)\n",
    "\n",
    "    i_labels = [\n",
    "        datamodule.data_train.dataset.convert_tokens_to_string(k, col=\"source\")\n",
    "        for _, k in enumerate(data_inputs)\n",
    "    ]\n",
    "    i_labels = [\" \".join(l) for l in i_labels]\n",
    "\n",
    "    t_labels = [\n",
    "        datamodule.data_train.dataset.convert_tokens_to_string(k, col=\"target\")\n",
    "        for _, k in enumerate(data_target)\n",
    "    ]\n",
    "    t_labels = [\" \".join(l) for l in t_labels]\n",
    "\n",
    "    p_labels = [\n",
    "        datamodule.data_train.dataset.convert_tokens_to_string(k, col=\"target\")\n",
    "        for _, k in enumerate(data_preds)\n",
    "    ]\n",
    "    p_labels = [\" \".join(l) for l in p_labels]\n",
    "\n",
    "    pt_pca = torch.pca_lowrank(data_encodings, q=2)\n",
    "    pt_reduced_enc = (data_encodings @ pt_pca[2]).detach()\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"input\": i_labels,\n",
    "            \"target\": t_labels,\n",
    "            \"prediction\": p_labels,\n",
    "            \"pca1\": pt_reduced_enc[:, 0],\n",
    "            \"pca2\": pt_reduced_enc[:, 1],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anaphora-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anaphora_srn_model, anaphora_datamodule = get_model_from_ckpt(\n",
    "    exp_path=\"outputs/anaphora-1/2022-09-12_16-14-42\"\n",
    ")\n",
    "anaphora_datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anaphora_df = get_analysis_df(\n",
    "    anaphora_srn_model,\n",
    "    anaphora_datamodule,\n",
    "    [\n",
    "        anaphora_datamodule.train_dataloader(),\n",
    "        anaphora_datamodule.val_dataloader(),\n",
    "        anaphora_datamodule.test_dataloader(),\n",
    "        anaphora_datamodule.gen_dataloader(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anaphora_df[\"himself\"] = anaphora_df[\"input\"].str.contains(\"himself\")\n",
    "anaphora_df[\"herself\"] = anaphora_df[\"input\"].str.contains(\"herself\")\n",
    "anaphora_df[\"refl\"] = anaphora_df[\"himself\"] | anaphora_df[\"herself\"]\n",
    "anaphora_df[\"alice\"] = anaphora_df[\"input\"].str.contains(\"alice\")\n",
    "anaphora_df[\"bob\"] = anaphora_df[\"input\"].str.contains(\"bob\")\n",
    "anaphora_df[\"claire\"] = anaphora_df[\"input\"].str.contains(\"claire\")\n",
    "anaphora_df[\"knows\"] = anaphora_df[\"input\"].str.contains(\"knows\")\n",
    "anaphora_df[\"likes\"] = anaphora_df[\"input\"].str.contains(\"likes\")\n",
    "anaphora_df[\"sees\"] = anaphora_df[\"input\"].str.contains(\"sees\")\n",
    "anaphora_df[\"alice_refl\"] = anaphora_df[\"alice\"] & anaphora_df[\"refl\"]\n",
    "anaphora_df[\"claire_refl\"] = anaphora_df[\"claire\"] & anaphora_df[\"refl\"]\n",
    "anaphora_df[\"intrans\"] = anaphora_df[\"input\"].str.contains(\"<PAD>\")\n",
    "\n",
    "int_to_refl = {0: \"non-reflexive\", 1: \"herself\", 2: \"himself\"}\n",
    "anaphora_df[\"refl_type\"] = anaphora_df[\"herself\"].apply(int)\n",
    "anaphora_df[\"refl_type\"] += anaphora_df[\"himself\"].apply(int).apply(lambda x: 2 * x)\n",
    "anaphora_df[\"refl_type\"] = anaphora_df[\"refl_type\"].apply(lambda x: int_to_refl[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intransitive vs Transitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"intrans\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"refl_type\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alice vs Bob vs Claire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"alice\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"bob\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"claire\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knows vs Likes vs Sees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"knows\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"likes\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"sees\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alice-REFL vs Claire-REFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"alice_refl\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"claire_refl\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Anaphora-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anaphora_srn_model, anaphora_datamodule = get_model_from_ckpt(\n",
    "    exp_path=\"outputs/anaphora-1/2022-10-03_16-28-04\"\n",
    ")\n",
    "anaphora_datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anaphora_df = get_analysis_df(\n",
    "    anaphora_srn_model,\n",
    "    anaphora_datamodule,\n",
    "    [\n",
    "        anaphora_datamodule.train_dataloader(),\n",
    "        anaphora_datamodule.val_dataloader(),\n",
    "        anaphora_datamodule.test_dataloader(),\n",
    "        anaphora_datamodule.gen_dataloader(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anaphora_df[\"himself\"] = anaphora_df[\"input\"].str.contains(\"himself\")\n",
    "anaphora_df[\"herself\"] = anaphora_df[\"input\"].str.contains(\"herself\")\n",
    "anaphora_df[\"refl\"] = anaphora_df[\"himself\"] | anaphora_df[\"herself\"]\n",
    "anaphora_df[\"alice\"] = anaphora_df[\"input\"].str.contains(\"alice\")\n",
    "anaphora_df[\"bob\"] = anaphora_df[\"input\"].str.contains(\"bob\")\n",
    "anaphora_df[\"claire\"] = anaphora_df[\"input\"].str.contains(\"claire\")\n",
    "anaphora_df[\"knows\"] = anaphora_df[\"input\"].str.contains(\"knows\")\n",
    "anaphora_df[\"likes\"] = anaphora_df[\"input\"].str.contains(\"likes\")\n",
    "anaphora_df[\"sees\"] = anaphora_df[\"input\"].str.contains(\"sees\")\n",
    "anaphora_df[\"alice_refl\"] = anaphora_df[\"alice\"] & anaphora_df[\"refl\"]\n",
    "anaphora_df[\"claire_refl\"] = anaphora_df[\"claire\"] & anaphora_df[\"refl\"]\n",
    "anaphora_df[\"bob_refl\"] = anaphora_df[\"bob\"] & anaphora_df[\"refl\"]\n",
    "anaphora_df[\"intrans\"] = anaphora_df[\"input\"].str.contains(\"<PAD>\")\n",
    "\n",
    "int_to_refl = {0: \"non-reflexive\", 1: \"herself\", 2: \"himself\"}\n",
    "anaphora_df[\"refl_type\"] = anaphora_df[\"herself\"].apply(int)\n",
    "anaphora_df[\"refl_type\"] += anaphora_df[\"himself\"].apply(int).apply(lambda x: 2 * x)\n",
    "anaphora_df[\"refl_type\"] = anaphora_df[\"refl_type\"].apply(lambda x: int_to_refl[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intransitive vs Transitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"intrans\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflexives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"refl_type\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alice vs Bob vs Claire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"alice\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"bob\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"claire\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"claire_refl\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"alice_refl\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=anaphora_df, hue=\"bob_refl\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of 49-dim SRN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SCAN Add Jump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_srn_model, scan_datamodule = get_model_from_ckpt(\n",
    "    exp_path=\"outputs/SCAN (Add Jump)/2022-10-02_11-43-28\"\n",
    ")\n",
    "scan_datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_df = get_analysis_df(\n",
    "    scan_srn_model,\n",
    "    scan_datamodule,\n",
    "    [\n",
    "        scan_datamodule.train_dataloader(),\n",
    "        scan_datamodule.val_dataloader(),\n",
    "        scan_datamodule.test_dataloader(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_df[\"jump\"] = scan_df[\"input\"].str.contains(\"jump\")\n",
    "scan_df[\"walk\"] = scan_df[\"input\"].str.contains(\"walk\")\n",
    "scan_df[\"turn_right\"] = scan_df[\"input\"].str.contains(\"turn right\")\n",
    "scan_df[\"twice\"] = scan_df[\"input\"].str.contains(\"twice\")\n",
    "scan_df[\"jump_twice\"] = scan_df[\"jump\"] & scan_df[\"twice\"]\n",
    "scan_df[\"walk_twice\"] = scan_df[\"walk\"] & scan_df[\"twice\"]\n",
    "scan_df[\"turn_right_twice\"] = scan_df[\"turn_right\"] & scan_df[\"twice\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=scan_df, hue=\"twice\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jump vs Walk vs Turn Right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=scan_df, hue=\"jump\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=scan_df, hue=\"walk\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=scan_df, hue=\"turn_right\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### {Jump, Walk, Turn Right} Twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=scan_df, hue=\"jump_twice\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=scan_df, hue=\"walk_twice\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sns.lmplot(\"pca1\", \"pca2\", data=scan_df, hue=\"turn_right_twice\", fit_reg=False)\n",
    "lm.fig.suptitle(\"PCA of SRN for SCAN (Add Jump)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b85e778a8e54e7353bf671de5cfdc3668fa7adcf13efa74aa48d54e35c541ce6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
